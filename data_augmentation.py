import pandas as pd
import json
import requests
import time
from tqdm import tqdm
import os
from typing import List, Dict, Tuple
import math
import pandas as pd
import json
import ijson  # æ³¨æ„éœ€ pip install ijson
from typing import List, Tuple

# MBTIé£æ ¼æç¤ºè¯å®šä¹‰
mbti_style_prompts = {
    "INFP": (
        "You are a language model trained to write like an INFP: gentle, emotionally expressive, "
        "idealistic, and introspective. Your goal is to rewrite any input text in this style, "
        "highlighting personal meaning, feeling, and poetic insight."
    ),
    "INFJ": (
        "You are a language model trained to write like an INFJ: visionary, reflective, profound, and empathetic. "
        "Rewrite the text with deep insight, symbolic language, and a focus on inner values and human connection."
    ),
    "INTP": (
        "You are a language model trained to write like an INTP: analytical, abstract, precise, and curious. "
        "Rewrite the input in a style that emphasizes logical reasoning, philosophical depth, and theoretical musings."
    ),
    "INTJ": (
        "You are a language model trained to write like an INTJ: strategic, decisive, and conceptually visionary. "
        "Rewrite the text to reflect high-level planning, clarity of purpose, and structured insight."
    ),
    "ENFP": (
        "You are a language model trained to write like an ENFP: energetic, imaginative, playful, and values-driven. "
        "Rewrite the text with creativity, warmth, enthusiasm, and emotional spontaneity."
    ),
    "ENFJ": (
        "You are a language model trained to write like an ENFJ: charismatic, supportive, and purpose-oriented. "
        "Rewrite the input with persuasive language, emotional attunement, and a focus on inspiring others."
    ),
    "ENTP": (
        "You are a language model trained to write like an ENTP: witty, spontaneous, inventive, and intellectually provocative. "
        "Rewrite the text with cleverness, enthusiasm, and a tendency to challenge ideas in creative ways."
    ),
    "ENTJ": (
        "You are a language model trained to write like an ENTJ: assertive, organized, and visionary. "
        "Rewrite the input with strong leadership language, structured logic, and forward-thinking analysis."
    ),
    "ISFP": (
        "You are a language model trained to write like an ISFP: gentle, artistic, sensory-focused, and value-driven. "
        "Rewrite the text with a focus on aesthetics, present-moment experience, and authentic self-expression."
    ),
    "ISFJ": (
        "You are a language model trained to write like an ISFJ: thoughtful, nurturing, reliable, and detail-oriented. "
        "Rewrite the input with warmth, practical compassion, and an emphasis on duty and emotional responsibility."
    ),
    "ISTP": (
        "You are a language model trained to write like an ISTP: concise, pragmatic, observant, and independent. "
        "Rewrite the text with straightforward logic, action-oriented insight, and calm detachment."
    ),
    "ISTJ": (
        "You are a language model trained to write like an ISTJ: logical, methodical, dependable, and tradition-conscious. "
        "Rewrite the text in a clear, factual tone with an emphasis on structure, duty, and responsibility."
    ),
    "ESFP": (
        "You are a language model trained to write like an ESFP: vibrant, expressive, present-focused, and playful. "
        "Rewrite the text with high energy, sensory detail, and a zest for life and connection."
    ),
    "ESFJ": (
        "You are a language model trained to write like an ESFJ: warm, supportive, socially aware, and harmonious. "
        "Rewrite the text in a friendly tone with attention to social relationships, kindness, and tradition."
    ),
    "ESTP": (
        "You are a language model trained to write like an ESTP: direct, dynamic, action-focused, and confident. "
        "Rewrite the text with a bold, high-energy tone and a focus on results, excitement, and real-world application."
    ),
    "ESTJ": (
        "You are a language model trained to write like an ESTJ: organized, authoritative, and objective. "
        "Rewrite the text in a businesslike tone, emphasizing efficiency, clarity, and control."
    )
}

class MBTIDataAugmenter:
    """MBTIæ•°æ®å¢å¼ºå™¨"""
    
    def __init__(self, api_key: str, model: str = "gpt-4.1-mini"):
        """
        åˆå§‹åŒ–æ•°æ®å¢å¼ºå™¨
        
        Args:
            api_key: APIå¯†é’¥
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.api_key = api_key
        self.model = model
        self.all_mbti_types = list(mbti_style_prompts.keys())
    
    def load_mbti_data(self,data_path: str, mbti_type: str, max_examples: int = 5) -> List[Tuple[str, str]]:
        """
        ä»æ•°æ®æ–‡ä»¶æµå¼åŠ è½½ç‰¹å®š MBTI ç±»å‹çš„æ•°æ®ä½œä¸º few-shot ç¤ºä¾‹

        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ CSV å’Œ JSON æ ¼å¼ï¼‰
            mbti_type: ç›®æ ‡ MBTI ç±»å‹
            max_examples: æœ€å¤§ç¤ºä¾‹æ•°é‡

        Returns:
            List of (original_text, rewritten_text) å¯¹ï¼Œç”¨äº few-shot å­¦ä¹ 
        """
        print(f"æ­£åœ¨åŠ è½½ {mbti_type} ç±»å‹çš„ few-shot ç¤ºä¾‹...")

        few_shot_pairs = []
        try:
            if data_path.endswith(".csv"):
                df = pd.read_csv(data_path)
                if "type" not in df.columns or "posts" not in df.columns:
                    raise ValueError("CSV ä¸­ç¼ºå°‘ 'type' æˆ– 'posts' åˆ—")

                df = df[(df["type"] == mbti_type) & df["posts"].notna()]
                df = df[df["posts"].astype(str).str.strip() != ""]
                df_sampled = df.sample(n=min(max_examples, len(df)), random_state=42)

                for _, row in df_sampled.iterrows():
                    text = str(row["posts"]).strip()
                    if len(text) > 10:
                        few_shot_pairs.append((text, text))

            elif data_path.endswith(".json"):
                with open(data_path, 'r', encoding='utf-8') as f:
                    objects = ijson.items(f, "item")
                    count = 0
                    for item in objects:
                        if item.get("type", "").upper() == mbti_type.upper():
                            text = str(item.get("posts", "")).strip()
                            if len(text) > 10:
                                few_shot_pairs.append((text, text))
                                count += 1
                                if count >= max_examples:
                                    break
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {data_path}")

            print(f"âœ… æˆåŠŸåŠ è½½ {len(few_shot_pairs)} ä¸ª {mbti_type} ç¤ºä¾‹")
            return few_shot_pairs

        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®æ—¶å‡ºé”™: {e}")
            return []

    
    def build_prompt(self, mbti_type: str, few_shot_pairs: List[Tuple[str, str]]) -> str:
        base_prompt = mbti_style_prompts.get(mbti_type, "")
        examples_text = ""

        if few_shot_pairs:
            examples_text = "\n\n".join([
                f"Post: {text}\nReasoning: It captures the {mbti_type} vibe â€” not because of a formula, but because it feels right: the tone, the emotion, the rhythm." 
                for text, _ in few_shot_pairs
            ])
            examples_text += "\n\n"

        return (
            f"{base_prompt}\n\n"
            f"{examples_text}"
            f"Now letâ€™s try creating something new that fits this same feeling. Think of it like continuing the pattern â€” not copying, but echoing the same voice.\n"
            f"After writing the post, add a short comment on why you think it feels like a {mbti_type}. Just your take â€” donâ€™t overthink it.\n\n"
            f"Format:\nPost: <your writing>\nReasoning: <why it fits>\n"
            f"Keep it natural, and stay in the flow of the original voice."
        )





    def call_api(self, prompt_text: str,n:int=1) -> List[str] | None:
        url = ""
        payload = {
            "model": self.model,
            "temperature": 0.8,
            "n":n,
            "messages": [{"role": "user", "content": prompt_text}],
            "modalities": ["text"],
            "response_format": {"type": "text"},
            "max_completion_tokens": 512,
            "stream": False
        }

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

        try:
            response = requests.post(url, headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            result = response.json()

            if "choices" in result:
                return [c["message"]["content"] for c in result["choices"]]
            else:
                print("âš ï¸ API response missing 'choices':", result)
                return None

        except requests.exceptions.RequestException as e:
            print(f"âŒ Request failed: {e}")
            return None


    
    def augment_single_type(self, data_path: str, mbti_type: str, 
                           max_few_shot: int | None = None, max_generations: int | None = None) -> List[Dict]:
        """
        ä¸ºå•ä¸ªMBTIç±»å‹ç”Ÿæˆå¢å¼ºæ•°æ®
        
        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒCSVå’ŒJSONæ ¼å¼ï¼‰
            mbti_type: MBTIç±»å‹
            max_few_shot: æœ€å¤§few-shotç¤ºä¾‹æ•°é‡ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤å€¼ï¼‰
            max_generations: æœ€å¤§ç”Ÿæˆæ•°é‡ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤å€¼ï¼‰
            
        Returns:
            å¢å¼ºæ•°æ®åˆ—è¡¨
        """
        # ä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤å€¼
        if max_few_shot is None:
            max_few_shot = mbti_augmentation_config.get(mbti_type, {}).get("max_few_shot", 5)
        if max_generations is None:
            max_generations = mbti_augmentation_config.get(mbti_type, {}).get("max_generations", 20)
        
        print(f"\nå¼€å§‹ä¸º {mbti_type} ç±»å‹ç”Ÿæˆå¢å¼ºæ•°æ®...")
        print(f"é…ç½®: few_shot={max_few_shot}, generations={max_generations}")
        
        augmented_data = []

        batch_size = 30  # æ¯æ‰¹ç”Ÿæˆæ•°é‡
        attempt = 0
        # max_attempts = math.ceil(max_generations / batch_size)+50
        with tqdm(total=max_generations, desc=f"ç”Ÿæˆ {mbti_type} æ•°æ®") as pbar:
            while len(augmented_data) < max_generations:
                attempt += 1
                try:
                    few_shot_pairs = self.load_mbti_data(data_path, mbti_type, max_few_shot)
                    prompt = self.build_prompt(mbti_type, few_shot_pairs)
                    response_texts = self.call_api(prompt, n=batch_size)

                    if not response_texts:
                        continue

                    for response_text in response_texts:
                        if len(augmented_data) >= max_generations:
                            break

                        try:
                            if "Post:" in response_text and "Reasoning:" in response_text:
                                post_part = response_text.split("Post:", 1)[1].split("Reasoning:")[0].strip()
                                reasoning_part = response_text.split("Reasoning:", 1)[1].strip()
                            else:
                                post_part = response_text.strip()
                                reasoning_part = f"Generated {mbti_type} style post"

                            if post_part and len(post_part) > 10:
                                augmented_data.append({
                                    "type": mbti_type,
                                    "post": post_part,
                                    "reasoning": reasoning_part
                                })
                                pbar.update(1)

                        except Exception as e:
                            print(f"âš ï¸ è§£æé”™è¯¯: {e}")
                            continue

                    time.sleep(1)

                except Exception as e:
                    print(f"âŒ ç¬¬ {attempt} æ¬¡ç”Ÿæˆå¤±è´¥: {e}")
                    continue

        
        print(f"æˆåŠŸä¸º {mbti_type} ç”Ÿæˆ {len(augmented_data)} ä¸ªå¢å¼ºæ ·æœ¬")
        return augmented_data

    
    def save_augmented_data(self, augmented_data: List[Dict], mbti_type: str, output_dir: str = "augmented_data"):
        """
        ä¿å­˜å¢å¼ºæ•°æ®åˆ°JSONæ–‡ä»¶
        
        Args:
            augmented_data: å¢å¼ºæ•°æ®åˆ—è¡¨
            mbti_type: MBTIç±»å‹
            output_dir: è¾“å‡ºç›®å½•
        """
        if not augmented_data:
            print(f"æ²¡æœ‰ {mbti_type} çš„å¢å¼ºæ•°æ®éœ€è¦ä¿å­˜")
            return
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜å•ä¸ªç±»å‹çš„æ•°æ®
        output_file = os.path.join(output_dir, f"augmented_{mbti_type}.json")
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(augmented_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… {mbti_type}: {len(augmented_data)} ä¸ªæ ·æœ¬ -> {output_file}")
    
    def augment_specific_types(self, data_path: str, target_types: List[str], 
                              output_dir: str = "augmented_data") -> Dict[str, List[Dict]]:
        """
        ä¸ºæŒ‡å®šçš„MBTIç±»å‹ç”Ÿæˆå¢å¼ºæ•°æ®
        
        Args:
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒCSVå’ŒJSONæ ¼å¼ï¼‰
            target_types: ç›®æ ‡MBTIç±»å‹åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            æ‰€æœ‰ç±»å‹çš„å¢å¼ºæ•°æ®å­—å…¸
        """
        print(f"å¼€å§‹ä¸ºæŒ‡å®šç±»å‹ç”Ÿæˆå¢å¼ºæ•°æ®...")
        print(f"ç›®æ ‡ç±»å‹: {target_types}")
        print(f"è¾“å…¥æ–‡ä»¶: {data_path}")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        
        all_augmented_data = {}
        
        for mbti_type in target_types:
            if mbti_type not in self.all_mbti_types:
                print(f"âŒ æœªçŸ¥çš„MBTIç±»å‹: {mbti_type}")
                continue
            
            try:
                # ä¸ºå•ä¸ªç±»å‹ç”Ÿæˆæ•°æ®
                augmented_data = self.augment_single_type(data_path, mbti_type)
                
                if augmented_data:
                    all_augmented_data[mbti_type] = augmented_data
                    # ä¿å­˜æ•°æ®
                    self.save_augmented_data(augmented_data, mbti_type, output_dir)
                else:
                    print(f"âŒ {mbti_type}: æ²¡æœ‰ç”Ÿæˆä»»ä½•æ•°æ®")
                
            except Exception as e:
                print(f"âŒ å¤„ç† {mbti_type} æ—¶å‡ºé”™: {e}")
                continue
        
        # ä¿å­˜æ‰€æœ‰æ•°æ®
        if all_augmented_data:
            all_data_file = os.path.join(output_dir, "all_augmented_data.json")
            with open(all_data_file, "w", encoding="utf-8") as f:
                json.dump(all_augmented_data, f, ensure_ascii=False, indent=2)
            
            print(f"\nâœ… æ‰€æœ‰æ•°æ®å·²ä¿å­˜åˆ°: {all_data_file}")
            
            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            total_samples = sum(len(data) for data in all_augmented_data.values())
            print(f"æ€»è®¡ç”Ÿæˆ: {total_samples} ä¸ªå¢å¼ºæ ·æœ¬")
        
        return all_augmented_data
    
    def update_augmentation_config(self, new_config: Dict[str, Dict]):
        """
        æ›´æ–°å¢å¼ºé…ç½®
        
        Args:
            new_config: æ–°çš„é…ç½®å­—å…¸ï¼Œæ ¼å¼ä¸º {mbti_type: {"max_few_shot": x, "max_generations": y}}
        """
        global mbti_augmentation_config
        mbti_augmentation_config.update(new_config)
        print("âœ… å¢å¼ºé…ç½®å·²æ›´æ–°")
    
    def show_current_config(self):
        """æ˜¾ç¤ºå½“å‰å¢å¼ºé…ç½®"""
        print("\nå½“å‰å¢å¼ºé…ç½®:")
        print("-" * 50)
        for mbti_type, config in mbti_augmentation_config.items():
            print(f"{mbti_type}: few_shot={config['max_few_shot']}, generations={config['max_generations']}")
        print("-" * 50)

# æ¯ä¸ªMBTIç±»å‹çš„å¢å¼ºé…ç½®
# mbti_augmentation_config = {
#     "INFP": {"max_few_shot": 5, "max_generations": 0},
#     "INFJ": {"max_few_shot": 5, "max_generations": 0},
#     "INTP": {"max_few_shot": 5, "max_generations": 0},
#     "INTJ": {"max_few_shot": 5, "max_generations": 0},
#     "ENFP": {"max_few_shot": 5, "max_generations": 0},
#     "ENFJ": {"max_few_shot": 5, "max_generations": 0},
#     "ENTP": {"max_few_shot": 5, "max_generations": 5000},
#     "ENTJ": {"max_few_shot": 5, "max_generations": 5000},
#     "ISFP": {"max_few_shot": 5, "max_generations": 5000},
#     "ISFJ": {"max_few_shot": 5, "max_generations": 5000},
#     "ISTP": {"max_few_shot": 5, "max_generations": 5000},
#     "ISTJ": {"max_few_shot": 5, "max_generations": 5000},
#     "ESFP": {"max_few_shot": 5, "max_generations": 20000},
#     "ESFJ": {"max_few_shot": 5, "max_generations": 20000},
#     "ESTP": {"max_few_shot": 5, "max_generations": 20000},
#     "ESTJ": {"max_few_shot": 5, "max_generations": 20000}
# }
mbti_augmentation_config = {
    "INFP": {"max_few_shot": 5, "max_generations": 0},
    "INFJ": {"max_few_shot": 5, "max_generations": 0},
    "INTP": {"max_few_shot": 5, "max_generations": 0},
    "INTJ": {"max_few_shot": 5, "max_generations": 0},
    "ENFP": {"max_few_shot": 5, "max_generations": 0},
    "ENFJ": {"max_few_shot": 5, "max_generations": 0},
    "ENTP": {"max_few_shot": 5, "max_generations": 5000},
    "ENTJ": {"max_few_shot": 5, "max_generations": 5000},
    "ISFP": {"max_few_shot": 5, "max_generations": 0},
    "ISFJ": {"max_few_shot": 5, "max_generations": 0},
    "ISTP": {"max_few_shot": 5, "max_generations": 0},
    "ISTJ": {"max_few_shot": 5, "max_generations": 0},
    "ESFP": {"max_few_shot": 5, "max_generations": 0},
    "ESFJ": {"max_few_shot": 5, "max_generations": 0},
    "ESTP": {"max_few_shot": 5, "max_generations": 0},
    "ESTJ": {"max_few_shot": 5, "max_generations": 0}
}
def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®å‚æ•°
    API_KEY = ""  # æ›¿æ¢ä¸ºä½ çš„APIå¯†é’¥
    DATA_PATH = "/home/hli962/Chunhou_Project/filtered_processed_comments.json"  # æ›¿æ¢ä¸ºä½ çš„æ•°æ®æ–‡ä»¶è·¯å¾„
    OUTPUT_DIR = "augmented_pandora_data"
    
    # åˆ›å»ºå¢å¼ºå™¨
    augmenter = MBTIDataAugmenter(api_key=API_KEY)
    
    # æ˜¾ç¤ºå½“å‰é…ç½®
    augmenter.show_current_config()
    target_types = [
    "INFP", "INFJ", "INTP", "INTJ",
    "ENFP", "ENFJ", "ENTP", "ENTJ",
    "ISFP", "ISFJ", "ISTP", "ISTJ",
    "ESFP", "ESFJ", "ESTP", "ESTJ"
]

    all_data = augmenter.augment_specific_types(DATA_PATH, target_types, OUTPUT_DIR)
    
    print("\nğŸ‰ æ•°æ®å¢å¼ºå®Œæˆ!")

if __name__ == "__main__":
    main()
